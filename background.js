// background.js
importScripts("config.js");
importScripts("whisper.js");
importScripts("openai.js");
chrome.runtime.onMessage.addListener((request, sender, sendResponse) => {
    console.log("ğŸ“© Mensaje recibido en background.js:", request.action);

    if (request.action === "transcribeAudio") {
        if (request.audioData) {
            console.log("ğŸ” Convirtiendo Base64 en Blob...");

            // Convertimos base64 a Blob
            const byteCharacters = atob(request.audioData.split(',')[1]);
            const byteNumbers = new Array(byteCharacters.length);
            for (let i = 0; i < byteCharacters.length; i++) {
                byteNumbers[i] = byteCharacters.charCodeAt(i);
            }
            const byteArray = new Uint8Array(byteNumbers);
            const audioBlob = new Blob([byteArray], { type: "audio/webm" });

            console.log("ğŸ“‚ Archivo de audio reconstruido:", audioBlob);
            console.log("ğŸ“ TamaÃ±o reconstruido:", audioBlob.size, "bytes");

            transcribeAudio(audioBlob)
                .then(transcription => {
                    console.log("âœ… TranscripciÃ³n recibida:", transcription);
                    sendResponse({ transcription });
                })
                .catch(error => {
                    console.error("ğŸš¨ Error en la transcripciÃ³n:", error);
                    sendResponse({ error: error.message });
                });

            return true; // Permite respuestas asÃ­ncronas
        } else {
            console.error("âŒ No se recibiÃ³ audio en la solicitud.");
            sendResponse({ error: "No se recibiÃ³ audio vÃ¡lido." });
        }
    }
});


//Crear ventana 
chrome.action.onClicked.addListener(() => {
    chrome.windows.create({
        url: "popup.html", // La interfaz de la extensiÃ³n
        type: "popup", // Ventana emergente
        width: 400,
        height: 500,
        top: 100,
        left: 100
    });
});
